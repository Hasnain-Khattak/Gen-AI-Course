{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ChatModels**\n",
    "\n",
    "> Chat models are language models that use a sequence of messages as inputs and return messages as outputs (as opposed to using plain text). These are generally newer models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain provides a unified interface for interacting with various chat models, which are advanced language models designed to process sequences of messages as inputs and produce message-based outputs. This design facilitates more natural and context-aware interactions compared to traditional models that handle plain text inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook we will try only open source LLMs so that everone can use them easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Groq Models\n",
    "2. Google Gemini\n",
    "3. Cohere\n",
    "4. Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-vertexai 2.0.11 requires httpx<0.29.0,>=0.28.0, but you have httpx 0.27.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-groq  -q\n",
    "!pip install langchain-google-genai  -q\n",
    "!pip install langchain-cohere  -q\n",
    "!pip install langchain-ollama  -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Google Gemini**\n",
    "\n",
    "Google AI offers a number of different chat models. For information on the latest models, their features, context windows, etc.\n",
    "\n",
    "We can Generate the Google Gemini API key from [here](https://aistudio.google.com/app/apikey?_gl=1*mdi8g8*_ga*MTIwNDM4ODc1OC4xNzMxOTI2MjA2*_ga_P1DBVKWT6V*MTczNjk0ODkyMC4xMS4xLjE3MzY5NDg5NTYuMjQuMC4xMzA3OTY4Mjk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0.5,\n",
    "    api_key=\"Your-API-KEY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to spanish. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"My heart say something\"),\n",
    "]\n",
    "\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ChatGroq**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the Groq API from [here](https://console.groq.com/keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select the Groq Model From [here](https://console.groq.com/docs/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(api_key=\"Your-API-KEY\",\n",
    "                 model='llama-3.1-8b-instant',\n",
    "                 temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Me encanta programar.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 55, 'total_tokens': 62, 'completion_time': 0.009333333, 'prompt_time': 0.004431735, 'queue_time': 0.052885888, 'total_time': 0.013765068}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c5e685ab6f', 'finish_reason': 'stop', 'logprobs': None}, id='run-bbb49dc2-578a-46d3-badd-544cc0795c3e-0', usage_metadata={'input_tokens': 55, 'output_tokens': 7, 'total_tokens': 62})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to spanish. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "\n",
    "ai_msg = model.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', \"You are a helpful assistant whose responsibility is to guide students in mathematics.\"),\n",
    "    ('human',\"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculus is a branch of mathematics that deals with the study of continuous change, particularly in the context of functions and limits. It's a fundamental subject that has numerous applications in various fields, including physics, engineering, economics, and computer science.\n",
      "\n",
      "Calculus consists of two main branches:\n",
      "\n",
      "1. **Differential Calculus**: This branch deals with the study of rates of change and slopes of curves. It helps us understand how functions change as their input changes. The main concept in differential calculus is the derivative, which represents the rate of change of a function with respect to its input.\n",
      "\n",
      "2. **Integral Calculus**: This branch deals with the study of accumulation of quantities. It helps us find the area under curves, volumes of solids, and other quantities. The main concept in integral calculus is the definite integral, which represents the accumulation of a function over a given interval.\n",
      "\n",
      "Calculus has many real-world applications, such as:\n",
      "\n",
      "- **Physics and Engineering**: Calculus is used to describe the motion of objects, including their position, velocity, and acceleration.\n",
      "- **Economics**: Calculus is used to model economic systems, including supply and demand curves, and to optimize economic outcomes.\n",
      "- **Computer Science**: Calculus is used in machine learning, computer graphics, and other areas of computer science.\n",
      "- **Biology**: Calculus is used to model population growth, disease spread, and other biological processes.\n",
      "\n",
      "Some of the key concepts in calculus include:\n",
      "\n",
      "- **Limits**: The concept of a limit is used to define the derivative and the definite integral.\n",
      "- **Derivatives**: Derivatives represent the rate of change of a function with respect to its input.\n",
      "- **Integrals**: Integrals represent the accumulation of a function over a given interval.\n",
      "- **Optimization**: Calculus is used to optimize functions, which is essential in many real-world applications.\n",
      "\n",
      "Overall, calculus is a powerful tool for understanding and analyzing complex phenomena, and it has numerous applications in various fields.\n",
      "\n",
      "Would you like to know more about a specific topic in calculus?\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'input': 'What is calculus?'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ChatCohere**\n",
    "\n",
    "You can get the API key from [here](https://dashboard.cohere.com/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "model = ChatCohere(cohere_api_key=\"Your-API-KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Te amo.', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'cf475a2e-ec04-4277-8734-bcd5bd45aab6', 'token_count': {'input_tokens': 225.0, 'output_tokens': 3.0}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'cf475a2e-ec04-4277-8734-bcd5bd45aab6', 'token_count': {'input_tokens': 225.0, 'output_tokens': 3.0}}, id='run-426a079f-790b-4333-9ba6-3008b0174224-0', usage_metadata={'input_tokens': 225, 'output_tokens': 3, 'total_tokens': 228})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to spanish. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love You.\"),\n",
    "]\n",
    "\n",
    "ai_msg = model.invoke(messages)\n",
    "ai_msg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
