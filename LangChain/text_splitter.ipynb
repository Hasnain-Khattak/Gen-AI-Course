{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LangChain Text Splitter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will go through different types of text splitters in `LangChain`. Each splitter has it's own advantage and way to split the data.\n",
    "\n",
    "Before doing into the deep of splitters we have to understand why there are so many splitters? And yeah by the ways we also called it as `chunking`.\n",
    "\n",
    "#### First let's take a look on what LangChain say about `Text splitters`:\n",
    "\n",
    "> Document splitting is often a crucial preprocessing step for many applications. It involves breaking down large texts into smaller, manageable chunks. This process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems. There are several strategies for splitting documents, each with its own advantages.\n",
    "\n",
    "\n",
    "There are so many types of Loaders, each loader has it's own limitations and used for different types of documents.\n",
    "\n",
    "Like `PyPDFLoader` is used to load PDFs, `WebBaseLoader` are used to load web pages. In the same way different splitters are used for different tasks, depending on what we need to split.\n",
    "\n",
    "Some of the Common Splitters in LangChain are:\n",
    "\n",
    "\n",
    "1. `CharacterTextSplitter` - Splits text based on character count, ensuring each chunk stays under a specified length.\n",
    "   \n",
    "2. `RecursiveCharacterTextSplitter` - Splits text hierarchically by breaking it down into smaller sections while respecting delimiters like paragraphs or sentences.\n",
    "   \n",
    "3. `MarkdownTextSplitter` - Splits text based on Markdown formatting, keeping logical structures like headings and lists intact.\n",
    "\n",
    "4. `TokenTextSplitter` - Splits text by token count, often using tokenizer models to match LLM tokenization logic.\n",
    "\n",
    "5. `LanguageSplitter` - Splits code files by programming language or structure.\n",
    "\n",
    "6. `PythonCodeSplitter` - Specializes in splitting Python code into logical units like functions or classes.\n",
    "\n",
    "7. `HTMLHeaderTextSplitter` - Splits HTML documents into meaningful parts such as tags, paragraphs, or sections.\n",
    "\n",
    "8.  `XMLSplitter` - Splits XML files while preserving the structure of nodes and tags.\n",
    "\n",
    "9.  `CustomSplitter` - A user-defined splitter for specialized splitting requirements\n",
    "\n",
    "10. `NLTKTextSplitter` - Splitting text using NLTK package. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `CharacterTextSplitter` to split the Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters:\n",
    "- separator: Delimiter for splitting (default: \" \").\n",
    "- chunk_size: Maximum size of each chunk.\n",
    "- chunk_overlap: Number of overlapping characters between chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('./Data/Central_Limit_Theorem.pdf')\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './Data/Central_Limit_Theorem.pdf', 'page': 0}, page_content='Bernoulli distribution is a probability distribution that models a binary outcome, where the \\noutcome can be either success (represented by the value 1) or failure (represented by the \\nvalue 0). The Bernoulli distribution is named after the Swiss mathematician Jacob Bernoulli, \\nwho first introduced it in the late 1600s.\\nThe Bernoulli distribution is characterized by a single parameter, which is the probability of \\nsuccess, denoted by p. The probability mass function (PMF) of the Bernoulli distribution is:\\nThe Bernoulli distribution is commonly used in machine learning for modelling \\nbinary outcomes, such as whether a customer will make a purchase or not, \\nwhether an email is spam or not, or whether a patient will have a certain disease \\nor not.\\nBernoulli Distribution\\n27 March 2023 16:06\\n   Session on Central Limit Theorem Page 1    ')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\", # Separator will help us to split the docs from where we want to split\n",
    "                                 chunk_size=120,\n",
    "                                 chunk_overlap=50) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most of the cases when we are dealing with this we often came accross these two methods in splitters.\n",
    "\n",
    "#### 1. split_documents\n",
    "#### 2. split_text\n",
    "\n",
    "#### Let's see what is the difference between both of them:\n",
    "\n",
    "The primary difference between split_text and split_documents in LangChain lies in what they process and the type of output they generate:\n",
    "\n",
    "- 1. split_text\n",
    "      - Purpose: Splits a single string of text into smaller chunks.\n",
    "      - Input: A single string (e.g., raw text or the contents of a file).\n",
    "      - Output: A list of strings, where each string is a chunk of the original text.\n",
    "      - Use Case: When you want to split raw text directly into manageable pieces, often for tasks like tokenization or summarization.\n",
    "- 2. split_documents\n",
    "      - Purpose: Splits multiple documents into chunks.\n",
    "      - Input: A list of documents, where each document is a dictionary with at least a page_content key containing text.\n",
    "      - Output: A list of dictionaries, where each dictionary is a chunk of a document and retains metadata.\n",
    "      - Use Case: When working with structured data (e.g., multiple documents) and you want to preserve metadata (e.g., document source, page number)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Use split_text for simple, unstructured text, and use split_documents for more complex workflows where you need to manage multiple documents along with their metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_text_splitters.base:Created a chunk of size 228, which is longer than the specified 120\n"
     ]
    }
   ],
   "source": [
    "splitter = CharacterTextSplitter(separator=\"\\n\", # Separator will help us to split the docs from where we want to split\n",
    "                                 chunk_size=120,\n",
    "                                 chunk_overlap=50) \n",
    "\n",
    "text = \"\"\"Document splitting is often a crucial preprocessing step for many applications.\n",
    "It involves breaking down large texts into smaller, manageable chunks. \n",
    "This process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems. \n",
    "There are several strategies for splitting documents, each with its own advantages.\"\"\"\n",
    "\n",
    "chunk = splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Document splitting is often a crucial preprocessing step for many applications.',\n",
       " 'It involves breaking down large texts into smaller, manageable chunks.',\n",
       " 'This process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems.',\n",
       " 'There are several strategies for splitting documents, each with its own advantages.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `RecursiveSplitter` to split the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.word_document import Docx2txtLoader\n",
    "\n",
    "loader = Docx2txtLoader('./Data/RAG_Types_Table.docx')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='RAG Types: Advantages, Disadvantages, Use Cases, and Additional Information\\n\\nRAG Type\\n\\nAdvantages\\n\\nDisadvantages\\n\\nWhen to Use\\n\\nAdditional Information\\n\\nHybrid RAG\\n\\n- High accuracy by combining multiple information sources\\n- Handles diverse types of data (structured, unstructured) well\\n- Robust in challenging scenarios\\n\\n- Complexity in implementation\\n- Higher computational resources required\\n- Increased latency\\n\\n- When accuracy is paramount, and there are multiple data types\\n\\nCombines retrieval-based techniques (like search engines or databases) and generation-based techniques (like GPT-based models) to provide comprehensive responses.\\n\\nGenerative RAG\\n\\n- Provides flexible and creative responses\\n- Can generate human-like content\\n- Capable of handling open-domain questions\\n\\n- Risk of generating hallucinated information\\n- Requires more extensive training data\\n\\n- For open-ended or creative tasks, generating human-like answers\\n\\nFocuses more on generative approaches by leveraging large language models (LLMs) to generate answers, which may include context-based information fetched from external sources.\\n\\nRetrieval RAG\\n\\n- Provides precise, contextually relevant information\\n- Efficiently scales with large data\\n- Suitable for factual accuracy\\n\\n- Limited flexibility in response generation\\n- May not adapt well to highly abstract or creative tasks\\n\\n- When factual correctness is a priority\\n\\nPrimarily relies on robust retrieval systems such as search engines or database queries to provide pre-fetched content that is more factual and contextually accurate.\\n\\nKnowledge-based RAG\\n\\n- Integrates domain-specific knowledge\\n- High reliability in specific domains\\n- Supports real-time information and knowledge updates\\n\\n- Limited to the knowledge base updates\\n- May not perform well in general contexts\\n\\n- When domain-specific knowledge is required\\n\\nUses a structured knowledge base to answer questions, making it ideal for use cases like medical consultations, technical troubleshooting, and specialized customer support.\\n\\nEnd-to-End RAG\\n\\n- Seamless integration of retrieval and generation\\n- Provides a unified framework\\n- Can be fine-tuned for specific applications\\n\\n- Difficult to debug errors in responses\\n- High model complexity\\n\\n- When there is a need for streamlined, single-model architecture\\n\\nThese RAG systems combine both retrieval and generation processes in a tightly integrated end-to-end model, making them suitable for applications requiring high cohesion between information retrieval and generation.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.character import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='RAG Types: Advantages, Disadvantages, Use Cases, and Additional Information\\n\\nRAG Type\\n\\nAdvantages'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Disadvantages\\n\\nWhen to Use\\n\\nAdditional Information\\n\\nHybrid RAG'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- High accuracy by combining multiple information sources'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Handles diverse types of data (structured, unstructured) well\\n- Robust in challenging scenarios'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Complexity in implementation\\n- Higher computational resources required\\n- Increased latency'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- When accuracy is paramount, and there are multiple data types'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Combines retrieval-based techniques (like search engines or databases) and generation-based'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='techniques (like GPT-based models) to provide comprehensive responses'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='.'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Generative RAG'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Provides flexible and creative responses\\n- Can generate human-like content'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Capable of handling open-domain questions'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Risk of generating hallucinated information\\n- Requires more extensive training data'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- For open-ended or creative tasks, generating human-like answers'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Focuses more on generative approaches by leveraging large language models (LLMs) to generate'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='answers, which may include context-based information fetched from external sources'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='.'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Retrieval RAG'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Provides precise, contextually relevant information\\n- Efficiently scales with large data'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Suitable for factual accuracy'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Limited flexibility in response generation'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- May not adapt well to highly abstract or creative tasks'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- When factual correctness is a priority'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Primarily relies on robust retrieval systems such as search engines or database queries to provide'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='pre-fetched content that is more factual and contextually accurate'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='.'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Knowledge-based RAG'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Integrates domain-specific knowledge\\n- High reliability in specific domains'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Supports real-time information and knowledge updates'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Limited to the knowledge base updates\\n- May not perform well in general contexts'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- When domain-specific knowledge is required'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Uses a structured knowledge base to answer questions, making it ideal for use cases like medical'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='consultations, technical troubleshooting, and specialized customer support'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='.'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='End-to-End RAG'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Seamless integration of retrieval and generation\\n- Provides a unified framework'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Can be fine-tuned for specific applications'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Difficult to debug errors in responses\\n- High model complexity'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- When there is a need for streamlined, single-model architecture'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='These RAG systems combine both retrieval and generation processes in a tightly integrated'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='end-to-end model, making them suitable for applications requiring high cohesion between information'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='retrieval and generation'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='.')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "chunk = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Document splitting is often a crucial preprocessing step for many applications.',\n",
       " 'It involves breaking down large texts into smaller, manageable chunks.',\n",
       " 'This process offers several benefits, such as ensuring consistent processing of varying document',\n",
       " 'lengths, overcoming input size limitations of models, and improving the quality of text',\n",
       " 'representations used in retrieval systems',\n",
       " '.',\n",
       " 'There are several strategies for splitting documents, each with its own advantages.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `TokenTextSplitter` to split the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different methods to split our Data into tokens.\n",
    "\n",
    "We can use `TokenTextSplitter` and also with `CharacterTextSplitter` and `RecursiveCharacterTextSplitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.base import TokenTextSplitter\n",
    "\n",
    "splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "\n",
    "chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Document splitting is often a crucial preprocessing step for many applications.\\nIt involves breaking down large texts into smaller, manageable chunks. \\nThis process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems. \\nThere are several strategies for splitting documents, each with its own advantages.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=100, chunk_overlap=0\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=100, chunk_overlap=0\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `MarkdownTextSplitter` to split markdown files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "loader = UnstructuredMarkdownLoader('./Data/mark.md')\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './Data/mark.md'}, page_content='Hello\\n\\nHello\\n\\nHello\\n\\nHello\\n\\nThis is my book\\n\\nThis is my book\\n\\nThis is my book.\\n\\nThis is my book\\n\\nHi\\n\\n__Hello__\\n\\nhello\\n\\nhello\\n\\nHello\\n\\nHi\\n\\nhi\\n\\nHello\\n\\nHello\\n\\nhi\\\\\\n\\nBooks\\n\\nThis is my book')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.markdown import MarkdownTextSplitter\n",
    "splitter = MarkdownTextSplitter(chunk_size=50, chunk_overlap=0)\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Data/mark.md'}, page_content='Hello\\n\\nHello\\n\\nHello\\n\\nHello\\n\\nThis is my book'),\n",
       " Document(metadata={'source': './Data/mark.md'}, page_content='This is my book\\n\\nThis is my book.'),\n",
       " Document(metadata={'source': './Data/mark.md'}, page_content='This is my book\\n\\nHi\\n\\n__Hello__\\n\\nhello\\n\\nhello'),\n",
       " Document(metadata={'source': './Data/mark.md'}, page_content='Hello\\n\\nHi\\n\\nhi\\n\\nHello\\n\\nHello\\n\\nhi\\\\\\n\\nBooks'),\n",
       " Document(metadata={'source': './Data/mark.md'}, page_content='This is my book')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split `language code` using `LanguageSplitter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RecursiveCharacterTextSplitter` includes pre-built lists of separators that are useful for splitting text in a specific programming language.\n",
    "\n",
    "Supported languages are stored in the langchain_text_splitters.Language enum. They include:\n",
    "\n",
    "\"cpp\",\n",
    "\"go\",\n",
    "\"java\",\n",
    "\"kotlin\",\n",
    "\"js\",\n",
    "\"ts\",\n",
    "\"php\",\n",
    "\"proto\",\n",
    "\"python\",\n",
    "\"rst\",\n",
    "\"ruby\",\n",
    "\"rust\",\n",
    "\"scala\",\n",
    "\"swift\",\n",
    "\"markdown\",\n",
    "\"latex\",\n",
    "\"html\",\n",
    "\"sol\",\n",
    "\"csharp\",\n",
    "\"cobol\",\n",
    "\"c\",\n",
    "\"lua\",\n",
    "\"perl\",\n",
    "\"haskell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
    "\n",
    "JS_CODE = \"\"\"\n",
    "function helloWorld() {\n",
    "  console.log(\"Hello, World!\");\n",
    "}\n",
    "\n",
    "// Call the function\n",
    "helloWorld();\n",
    "\"\"\"\n",
    "\n",
    "js_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.JS, chunk_size=60, chunk_overlap=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='function helloWorld() {\\n  console.log(\"Hello, World!\");\\n}'),\n",
       " Document(metadata={}, page_content='// Call the function\\nhelloWorld();')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_docs = js_splitter.create_documents([JS_CODE])\n",
    "js_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='<!DOCTYPE html>\\n<html>'),\n",
       " Document(metadata={}, page_content='<head>\\n        <title>ü¶úÔ∏èüîó LangChain</title>'),\n",
       " Document(metadata={}, page_content='<style>\\n            body {\\n                font-family: Aria'),\n",
       " Document(metadata={}, page_content='l, sans-serif;\\n            }\\n            h1 {'),\n",
       " Document(metadata={}, page_content='color: darkblue;\\n            }\\n        </style>\\n    </head'),\n",
       " Document(metadata={}, page_content='>'),\n",
       " Document(metadata={}, page_content='<body>'),\n",
       " Document(metadata={}, page_content='<div>\\n            <h1>ü¶úÔ∏èüîó LangChain</h1>'),\n",
       " Document(metadata={}, page_content='<p>‚ö° Building applications with LLMs through composability ‚ö°'),\n",
       " Document(metadata={}, page_content='</p>\\n        </div>'),\n",
       " Document(metadata={}, page_content='<div>\\n            As an open-source project in a rapidly dev'),\n",
       " Document(metadata={}, page_content='eloping field, we are extremely open to contributions.'),\n",
       " Document(metadata={}, page_content='</div>\\n    </body>\\n</html>')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_text = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>ü¶úÔ∏èüîó LangChain</title>\n",
    "        <style>\n",
    "            body {\n",
    "                font-family: Arial, sans-serif;\n",
    "            }\n",
    "            h1 {\n",
    "                color: darkblue;\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div>\n",
    "            <h1>ü¶úÔ∏èüîó LangChain</h1>\n",
    "            <p>‚ö° Building applications with LLMs through composability ‚ö°</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            As an open-source project in a rapidly developing field, we are extremely open to contributions.\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "html_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.HTML, chunk_size=60, chunk_overlap=0\n",
    ")\n",
    "html_docs = html_splitter.create_documents([html_text])\n",
    "html_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='def hello_world():\\n    print(\"Hello, World!\")'),\n",
       " Document(metadata={}, page_content='# Call the function\\nhello_world()')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `HTMLHeaderTextSplitter` to split HTML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "\n",
    "loader = BSHTMLLoader('./Data/langchain.html')\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='\\n\\nBSHTMLLoader | ü¶úÔ∏èüîó LangChain\\n\\n\\n\\n\\n\\n\\nSkip to main contentIntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1üí¨SearchKProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAcreomActiveloop Deep LakeAerospikeAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)BrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextCouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeepSparseDiffbotDingoDBDiscordDocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDSPyDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFalkorDBFaunaFiddlerFigmaFireCrawlFireworks AIFlyteForefront AIFriendli AIGeopandasGitGitBookGitHubGitLabGoldenGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraphsignalGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK√πzuLabel StudiolakeFSLanceDBLangChain Decorators ‚ú®LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariTalkMarqoMediaWikiDumpMeilisearchMemcachedMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot√∂rheadMyScaleNAVERNeo4jNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesPandasPebbloPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPremAIPromptLayerPsychicPubMedPullMd LoaderPygmalionAIQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRWKV-4Salute DevicesSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStoreDBscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)NebulaTairTelegramTencentTensorFlow DatasetsTiDBTigerGraphTigrisTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchVDMSVearchVectaraVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterxAIXataXorbits Inference (Xinference)YahooYandexYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizComponentsChat modelsChat modelsAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflare Workers AICohereCoze ChatDappier AIDatabricksDeepInfraEden AIErnie Bot ChatEverlyAIFireworksChatFriendliGigaChatGoogle AIGoogle Cloud Vertex AIGPTRouterGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLiteLLM RouterLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityChatPredictionGuardPremAIPromptLayer ChatOpenAIRekaSambaNovaCloudSambaStudioSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevLLM ChatVolc Enging MaasWriterxAIYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCohere rerankerCohere RAGDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGoogle DriveGoogle Vertex AI SearchIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalMilvus Hybrid SearchNanoPQ (Product Quantization)needleOutlinePinecone Hybrid SearchPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSingleStoreDBSVMTavilySearchAPITF-IDF**NeuralDB**VespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineTools/ToolkitsToolsAINetwork ToolkitAlpha VantageAmadeus ToolkitArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchE2B Data AnalysisEden AIEleven Labs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitGithub ToolkitGitlab ToolkitGmail ToolkitGolden QueryGoogle BooksGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksInfobipIonic Shopping ToolJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenWeatherMapOracle AI Vector Search: Generate SummaryPandas DataframePassio NutritionAIPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTavily SearchTwilioUpstageWikidataWikipediaWolfram AlphaYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modePandas DataFrameparsersPDFMinerPDFPlumberPebblo Safe DocumentLoaderPolars DataFramePsychicPubMedPullMdLoaderPyMuPDFPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCouchbaseDashVectorDatabricksDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconeQdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStoreDBscikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdIntel\\'s Visual Data Management System (VDMS)VearchVectaraVespaviking DBvliteWeaviateXataYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGigaChatGoogle Generative AI EmbeddingsGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel¬Æ Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsDocument loadersBSHTMLLoaderOn this pageBSHTMLLoader\\nThis notebook provides a quick overview for getting started with BeautifulSoup4 document loader. For detailed documentation of all __ModuleName__Loader features and configurations head to the API reference.\\nOverview\\u200b\\nIntegration details\\u200b\\nClassPackageLocalSerializableJS supportBSHTMLLoaderlangchain_community‚úÖ‚ùå‚ùå\\nLoader features\\u200b\\nSourceDocument Lazy LoadingNative Async SupportBSHTMLLoader‚úÖ‚ùå\\nSetup\\u200b\\nTo access BSHTMLLoader document loader you\\'ll need to install the langchain-community integration package and the bs4 python package.\\nCredentials\\u200b\\nNo credentials are needed to use the BSHTMLLoader class.\\nIf you want to get automated best in-class tracing of your model calls you can also set your LangSmith API key by uncommenting below:\\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\\nInstallation\\u200b\\nInstall langchain_community and bs4.\\n%pip install -qU langchain_community bs4\\nInitialization\\u200b\\nNow we can instantiate our model object and load documents:\\n\\nTODO: Update model instantiation with relevant params.\\n\\nfrom langchain_community.document_loaders import BSHTMLLoaderloader = BSHTMLLoader(    file_path=\"./example_data/fake-content.html\",)API Reference:BSHTMLLoader\\nLoad\\u200b\\ndocs = loader.load()docs[0]\\nDocument(metadata={\\'source\\': \\'./example_data/fake-content.html\\', \\'title\\': \\'Test Title\\'}, page_content=\\'\\\\nTest Title\\\\n\\\\n\\\\nMy First Heading\\\\nMy first paragraph.\\\\n\\\\n\\\\n\\')\\nprint(docs[0].metadata)\\n{\\'source\\': \\'./example_data/fake-content.html\\', \\'title\\': \\'Test Title\\'}\\nLazy Load\\u200b\\npage = []for doc in loader.lazy_load():    page.append(doc)    if len(page) >= 10:        # do some paged operation, e.g.        # index.upsert(page)        page = []page[0]\\nDocument(metadata={\\'source\\': \\'./example_data/fake-content.html\\', \\'title\\': \\'Test Title\\'}, page_content=\\'\\\\nTest Title\\\\n\\\\n\\\\nMy First Heading\\\\nMy first paragraph.\\\\n\\\\n\\\\n\\')\\nAdding separator to BS4\\u200b\\nWe can also pass a separator to use when calling get_text on the soup\\nloader = BSHTMLLoader(    file_path=\"./example_data/fake-content.html\", get_text_separator=\", \")docs = loader.load()print(docs[0])\\npage_content=\\', Test Title, , , , My First Heading, , My first paragraph., , , \\' metadata={\\'source\\': \\'./example_data/fake-content.html\\', \\'title\\': \\'Test Title\\'}\\nAPI reference\\u200b\\nFor detailed documentation of all BSHTMLLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.html_bs.BSHTMLLoader.html\\nRelated\\u200b\\n\\nDocument loader conceptual guide\\nDocument loader how-to guides\\nEdit this pageWas this page helpful?PreviousBrowserlessNextCassandraOverviewIntegration detailsLoader featuresSetupCredentialsInstallationInitializationLoadLazy LoadAdding separator to BS4API referenceRelatedCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2025 LangChain, Inc.\\n')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.html import HTMLHeaderTextSplitter\n",
    "\n",
    "splitter = HTMLHeaderTextSplitter(headers_to_split_on=[\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='BSHTMLLoader | ü¶úÔ∏èüîó LangChain\\n\\n\\n\\n\\n\\n\\nSkip to main contentInt'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='egrationsAPI ReferenceMoreContributingPeopleError referenceL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='angSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='1üí¨SearchKProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='nAIMoreProvidersAcreomActiveloop Deep LakeAerospikeAI21 Labs'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='AimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAn'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='alyticDBAnnoyAnthropicAnyscaleApache Software FoundationApac'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='he DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxiv'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='AscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsBAAIBage'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='lBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='liBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Op'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='en Knowledge)BrowserbaseBrowserlessByteDanceCassandraCerebra'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='sCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpC'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='loudflareClovaCnosDBCogniSwitchCohereCollege ConfidentialCom'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='etConfident AIConfluenceConneryContextCouchbaseCozeCrateDBC'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='TransformersCTranslate2CubeDappierDashVectorDatabricksDatado'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='g TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeepS'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='parseDiffbotDingoDBDiscordDocArrayDoclingDoctranDocugamiDocu'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='saurusDriaDropboxDSPyDuckDBDuckDuckGo SearchE2BEden AIElasti'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='csearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNote'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ExaFacebook - MetaFalkorDBFalkorDBFaunaFiddlerFigmaFireCrawl'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Fireworks AIFlyteForefront AIFriendli AIGeopandasGitGitBookG'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='itHubGitLabGoldenGoogleSerper - Google Search APIGooseAIGPT4'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='AllGradientGraphsignalGrobidGroqGutenbergHacker NewsHazy Res'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='earchHeliconeHologresHTML to textHuaweiHugging FaceIBMIEIT S'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIugu'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='JaguarJavelin AI GatewayJina AIJohnsnowlabsJoplinKDB.AIKinet'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='icaKoboldAIKonkoKoNLPYK√πzuLabel StudiolakeFSLanceDBLangChain'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Decorators ‚ú®LanternLindormLinkupLiteLLMLlamaIndexLlama.cppL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='lamaEdgellamafileLLMonitorLocalAILog10MariTalkMarqoMediaWiki'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='DumpMeilisearchMemcachedMetalMicrosoftMilvusMindsDBMinimaxMi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='stralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeMod'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot√∂rheadMy'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ScaleNAVERNeo4jNLPCloudNomicNotion DBNucliaNVIDIAObsidianOce'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='anBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='GraphDBOpenAIOpenLLMOpenSearchOpenWeatherMapOracleAI Vector'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='SearchOutlineOutlinesPandasPebbloPerplexityPetalsPostgres Em'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='beddingPGVectorPineconePipelineAIPortkeyPredibasePrediction'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='GuardPremAIPromptLayerPsychicPubMedPullMd LoaderPygmalionAIQ'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='drantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembral'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='lReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRWKV-4Salut'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='e DevicesSAPScrapeGraph AISearchApiSearxNG Search APISemaDBS'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='erpAPIShale ProtocolSingleStoreDBscikit-learnSlackSnowflakes'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='paCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStocha'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='sticAIStreamlitStripeSupabase (Postgres)NebulaTairTelegramTe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ncentTensorFlow DatasetsTiDBTigerGraphTigrisTogether AI2Mark'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='downTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructur'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='edUpstageupstashUpTrainUSearchVDMSVearchVectaraVespavliteVoy'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ageAIWeights & BiasesWeights & Biases tracingWeights & Biase'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='s trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram Alp'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='haWriterxAIXataXorbits Inference (Xinference)YahooYandexYeag'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='er.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizComponentsCh'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='at modelsChat modelsAI21 LabsAlibaba Cloud PAI EASAnthropic['),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzur'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='e OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS Bedro'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ckCerebrasCloudflare Workers AICohereCoze ChatDappier AIData'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='bricksDeepInfraEden AIErnie Bot ChatEverlyAIFireworksChatFri'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='endliGigaChatGoogle AIGoogle Cloud Vertex AIGPTRouterGroqCha'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='tHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLiteLL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='M RouterLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniM'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='axMistralAIMLXModelScopeMoonshotNaverNVIDIA AI EndpointsChat'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='OCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerp'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='lexityChatPredictionGuardPremAIPromptLayer ChatOpenAIRekaSam'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='baNovaCloudSambaStudioSnowflake CortexsolarSparkLLM ChatNebu'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='la (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevLLM C'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='hatVolc Enging MaasWriterxAIYandexGPTChatYIYuan2.0ZHIPU AIRe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='trieversRetrieversActiveloop Deep MemoryAmazon KendraArceeAr'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='xivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBRE'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='EBS (Open Knowledge)ChaindeskChatGPT pluginCohere rerankerCo'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='here RAGDappierDocArrayDriaElasticSearch BM25ElasticsearchEm'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='bedchainFlashRank rerankerFleet AI ContextGoogle DriveGoogle'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Vertex AI SearchIBM watsonx.aiJaguarDB Vector DatabaseKay.a'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='iKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieve'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='rLLMLingua Document CompressorLOTR (Merger Retriever)MetalMi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='lvus Hybrid SearchNanoPQ (Product Quantization)needleOutline'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Pinecone Hybrid SearchPubMedQdrant Sparse VectorRAGatouilleR'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ePhraseQueryRememberizerSEC filingSelf-querying retrieversSi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ngleStoreDBSVMTavilySearchAPITF-IDF**NeuralDB**VespaWikipedi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='aYou.comZep CloudZep Open SourceZilliz Cloud PipelineTools/T'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oolkitsToolsAINetwork ToolkitAlpha VantageAmadeus ToolkitArX'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Services ToolkitAzure Container Apps dynamic sessionsShell ('),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='bash)Bearly Code InterpreterBing SearchBrave SearchCassandra'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitc'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='h ToolkitConnery Toolkit and ToolsDall-E Image GeneratorData'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='bricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo Sear'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='chE2B Data AnalysisEden AIEleven Labs Text2SpeechExa SearchF'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ile SystemFinancialDatasets ToolkitGithub ToolkitGitlab Tool'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='kitGmail ToolkitGolden QueryGoogle BooksGoogle Cloud Text-to'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoo'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='gle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle Serpe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='rGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a t'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oolIFTTT WebHooksInfobipIonic Shopping ToolJina SearchJira T'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oolkitJSON ToolkitLemon AgentLinkupSearchToolMemorizeMojeek'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='SearchMultiOn ToolkitNASA ToolkitNuclia UnderstandingNVIDIA'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Lan'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='guage API ToolkitsOpenWeatherMapOracle AI Vector Search: Gen'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='erate SummaryPandas DataframePassio NutritionAIPlayWright Br'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='owser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPubM'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='edPython REPLReddit SearchRequests ToolkitRiza Code Interpre'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='terRobocorp ToolkitSceneXplainScrapeGraphSearchApiSearxNG Se'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='archSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL T'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTav'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ily SearchTwilioUpstageWikidataWikipediaWolfram AlphaYahoo F'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='inance NewsYou.com SearchYouTubeZapier Natural Language Acti'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='onsZenGuard AIDocument loadersDocument loadersacreomAirbyteL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyt'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='e Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Sales'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='force (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='(Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Su'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='pport (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon Tex'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='tractApify DatasetArcGISArxivLoaderAssemblyAI Audio Transcri'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='liBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessB'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='SHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurre'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='nt LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semanti'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='c LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusau'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='rusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebo'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ok ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue Cata'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='logGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle Bigtab'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='leGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLG'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oogle Cloud SQL for PostgreSQLGoogle Cloud Storage Directory'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Google Cloud Storage FileGoogle Firestore in Datastore ModeG'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firest'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ore (Native Mode)Google Memorystore for RedisGoogle SpannerG'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiF'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter Not'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMast'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='odonMathPixPDFLoaderMediaWiki DumpMerge Documents Loadermhtm'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='lMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='PowerPointMicrosoft SharePointMicrosoft WordNear Blockchain'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Modern TreasuryMongoDBNeedle Document LoaderNews URLNotion D'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='B 2/2NucliaObsidianOpen Document Format (ODT)Open City DataO'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='racle Autonomous DatabaseOracle AI Vector Search: Document P'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='rocessingOrg-modePandas DataFrameparsersPDFMinerPDFPlumberPe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='bblo Safe DocumentLoaderPolars DataFramePsychicPubMedPullMdL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oaderPyMuPDFPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPy'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='SparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRoc'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ksetrspaceRSS FeedsRSTscrapflyScrapingAntSitemapSlackSnowfla'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='keSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ncent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2M'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='arkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoader'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='WhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas Da'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='taFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZ'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='eroxPDFLoaderVector storesVector storesActiveloop Deep LakeA'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='erospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisA'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='pertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mong'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='o vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaid'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='u Cloud ElasticSearch VectorSearchBaidu VectorDBApache Cassa'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ndraChromaClarifaiClickHouseCouchbaseDashVectorDatabricksDin'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='goDBDocArray HnswSearchDocArray InMemorySearchAmazon Documen'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='t DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElas'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGoogle'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cl'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoo'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='gle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feat'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ure StoreGoogle Vertex AI Vector SearchHippoHologresInfinisp'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='anJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='LMRailsManticoreSearch VectorStoreMarqoMeilisearchAmazon Mem'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='4j Vector IndexNucliaDBOceanbaseOpenSearchOracle AI Vector S'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='earch: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVect'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='orPineconeQdrantRedisRelytRocksetSAP HANA Cloud Vector Engin'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='eScaNNSemaDBSingleStoreDBscikit-learnSQLiteVecSQLite-VSSSQLS'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='erverStarRocksSupabase (Postgres)SurrealDBTablestoreTairTenc'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTim'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='escale Vector (Postgres)TypesenseUpstash VectorUSearchValdIn'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"tel's Visual Data Management System (VDMS)VearchVectaraVespa\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='viking DBvliteWeaviateXataYellowbrickZepZep CloudZillizEmbed'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaD'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='BAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticse'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='archEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='gaChatGoogle Generative AI EmbeddingsGoogle Vertex AIGPT4All'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='GradientHugging FaceIBM watsonx.aiInfinityInstruct Embedding'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='s on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPU'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='IPEX-LLM: Local BGE Embeddings on Intel GPUIntel¬Æ Extension'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='for Transformers Quantized Text EmbeddingsJinaJohn Snow Labs'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='LASER Language-Agnostic SEntence Representations Embeddings'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMis'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='tralAImodel2vecModelScopeMosaicMLNaverNLP CloudNomicNVIDIA N'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='IMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOp'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='enAIOpenVINOEmbedding Documents using Optimized and Quantize'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='d EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcl'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='oudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMak'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='erSambaNovaSelf HostedSentence Transformers on Hugging FaceS'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='olarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddin'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='gs InferenceTextEmbed - Embedding Inference ServerTitan Take'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='offTogether AIUpstageVolc EngineVoyage AIXorbits inference ('),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Xinference)YandexGPTZhipuAIOtherComponentsDocument loadersBS'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='HTMLLoaderOn this pageBSHTMLLoader\\nThis notebook provides a'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='quick overview for getting started with BeautifulSoup4 docum'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ent loader. For detailed documentation of all __ModuleName__'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Loader features and configurations head to the API reference'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='.\\nOverview\\u200b\\nIntegration details\\u200b\\nClassPackageLocalSerializab'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='leJS supportBSHTMLLoaderlangchain_community‚úÖ‚ùå‚ùå\\nLoader featur'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='es\\u200b\\nSourceDocument Lazy LoadingNative Async SupportBSHTMLLoa'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"der‚úÖ‚ùå\\nSetup\\u200b\\nTo access BSHTMLLoader document loader you'll n\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='eed to install the langchain-community integration package a'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='nd the bs4 python package.\\nCredentials\\u200b\\nNo credentials are n'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='eeded to use the BSHTMLLoader class.\\nIf you want to get auto'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='mated best in-class tracing of your model calls you can also'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='set your LangSmith API key by uncommenting below:\\n# os.envi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ron[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangS'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='mith API key: \")# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\\nI'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='nstallation\\u200b\\nInstall langchain_community and bs4.\\n%pip insta'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ll -qU langchain_community bs4\\nInitialization\\u200b\\nNow we can in'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='stantiate our model object and load documents:\\n\\nTODO: Update'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='model instantiation with relevant params.\\n\\nfrom langchain_c'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ommunity.document_loaders import BSHTMLLoaderloader = BSHTML'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Loader(    file_path=\"./example_data/fake-content.html\",)API'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Reference:BSHTMLLoader\\nLoad\\u200b\\ndocs = loader.load()docs[0]\\nDo'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"cument(metadata={'source': './example_data/fake-content.html\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"', 'title': 'Test Title'}, page_content='\\\\nTest Title\\\\n\\\\n\\\\nM\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"y First Heading\\\\nMy first paragraph.\\\\n\\\\n\\\\n')\\nprint(docs[0].m\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"etadata)\\n{'source': './example_data/fake-content.html', 'tit\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"le': 'Test Title'}\\nLazy Load\\u200b\\npage = []for doc in loader.laz\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='y_load():    page.append(doc)    if len(page) >= 10:'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='# do some paged operation, e.g.        # index.upsert(page)'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"page = []page[0]\\nDocument(metadata={'source': './exam\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"ple_data/fake-content.html', 'title': 'Test Title'}, page_co\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"ntent='\\\\nTest Title\\\\n\\\\n\\\\nMy First Heading\\\\nMy first paragrap\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"h.\\\\n\\\\n\\\\n')\\nAdding separator to BS4\\u200b\\nWe can also pass a separ\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ator to use when calling get_text on the soup\\nloader = BSHTM'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='LLoader(    file_path=\"./example_data/fake-content.html\", ge'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='t_text_separator=\", \")docs = loader.load()print(docs[0])\\npag'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"e_content=', Test Title, , , , My First Heading, , My first\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"paragraph., , , ' metadata={'source': './example_data/fake-c\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content=\"ontent.html', 'title': 'Test Title'}\\nAPI reference\\u200b\\nFor deta\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='iled documentation of all BSHTMLLoader features and configur'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ations head to the API reference: https://python.langchain.c'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='om/api_reference/community/document_loaders/langchain_commun'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ity.document_loaders.html_bs.BSHTMLLoader.html\\nRelated\\u200b\\n\\nDoc'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ument loader conceptual guide\\nDocument loader how-to guides'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='Edit this pageWas this page helpful?PreviousBrowserlessNextC'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='assandraOverviewIntegration detailsLoader featuresSetupCrede'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='ntialsInstallationInitializationLoadLazy LoadAdding separato'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='r to BS4API referenceRelatedCommunityTwitterGitHubOrganizati'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='onPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2025 LangCha'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | ü¶úÔ∏èüîó LangChain'}, page_content='in, Inc.')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_header_splits = html_splitter.split_documents(docs)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create our custom splitter using LangChain `TextSplitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Part1', 'Part2', 'Part3']\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import TextSplitter\n",
    "\n",
    "class CustomSplitter(TextSplitter):\n",
    "    def split_text(self, text):\n",
    "        # Your custom splitting logic\n",
    "        return text.split(\";\")\n",
    "\n",
    "splitter = CustomSplitter(chunk_size=100, chunk_overlap=10)\n",
    "chunks = splitter.split_text(\"Part1;Part2;Part3\")\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Document splitting is often a crucial preprocessing step for many applications.\\nIt involves breaking down large texts into smaller, manageable chunks. \\nThis process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems. \\nThere are several strategies for splitting documents, each with its own advantages.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also split the documents using `NLTKTextSplitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.nltk import NLTKTextSplitter\n",
    "\n",
    "splitter = NLTKTextSplitter()\n",
    "\n",
    "chunk = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Document splitting is often a crucial preprocessing step for many applications.\\n\\nIt involves breaking down large texts into smaller, manageable chunks.\\n\\nThis process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems.\\n\\nThere are several strategies for splitting documents, each with its own advantages.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split the Python code Specifically using `PythonCodeTextSplitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.python import PythonLoader\n",
    "\n",
    "loader = PythonLoader('./Data/sms.py')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.python import PythonCodeTextSplitter\n",
    "\n",
    "splitter = PythonCodeTextSplitter()\n",
    "\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Data/sms.py'}, page_content='# Step 1: Dictionary to store student data\\nstudents = {}\\n\\n\\n# Step 2: Function to add a new student\\ndef add_student():\\n    name = input(\"Enter student\\'s name: \").title()\\n    age = int(input(f\"Enter {name}\\'s age: \"))\\n    marks = float(input(f\"Enter {name}\\'s marks: \"))\\n\\n    # Add student to the dictionary\\n    students[name] = {\"age\": age, \"marks\": marks}\\n    print(f\"Student {name} added successfully!\")\\n\\n\\n# Step 3: Function to update student marks\\ndef update_marks():\\n    name = input(\"Enter the student\\'s name to update marks: \").title()\\n\\n    if name in students:\\n        new_marks = float(input(f\"Enter new marks for {name}: \"))\\n        students[name][\"marks\"] = new_marks\\n        print(f\"{name}\\'s marks updated to {new_marks}!\")\\n    else:\\n        print(f\"Student {name} not found!\")\\n\\n\\n# Step 4: Function to display a student\\'s details\\ndef display_student():\\n    name = input(\"Enter the student\\'s name to display details: \").title()\\n\\n    if name in students:\\n        print(f\"Name: {name}\")\\n        print(f\"Age: {students[name][\\'age\\']}\")\\n        print(f\"Marks: {students[name][\\'marks\\']}\")\\n    else:\\n        print(f\"Student {name} not found!\")\\n\\n\\n# Step 5: Function to display all students\\ndef display_all_students():\\n    if students:\\n        print(\"\\\\nAll Students:\")\\n        for name, details in students.items():\\n            print(f\"Name: {name}, Age: {details[\\'age\\']}, Marks: {details[\\'marks\\']}\")\\n    else:\\n        print(\"No students added yet.\")\\n\\n# Step 8: Main menu\\ndef menu():\\n    while True:\\n        print(\"\\\\n--- Student Management System ---\")\\n        print(\"1. Add a new student\")\\n        print(\"2. Update student marks\")\\n        print(\"3. Display a student\\'s details\")\\n        print(\"4. Display all students\")\\n        # print(\"5. Find the top student\")\\n        # print(\"6. Calculate average marks\")\\n        print(\"5. Exit\")\\n\\n        choice = int(input(\"Enter your choice: \"))\\n\\n        if choice == 1:\\n            add_student()\\n        elif choice == 2:\\n            update_marks()\\n        elif choice == 3:\\n            display_student()\\n        elif choice == 4:\\n            display_all_students()\\n        elif choice == 5:\\n            print(\"Exiting the system. Goodbye!\")\\n            break\\n        else:\\n            print(\"Invalid choice. Please try again.\")\\n\\n\\n# Start the Student Management System\\nmenu()')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
