{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LangChain Text Splitter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will go through different types of text splitters in `LangChain`. Each splitter has it's own advantage and way to split the data.\n",
    "\n",
    "Before doing into the deep of splitters we have to understand why there are so many splitters? And yeah by the ways we also called it as `chunking`.\n",
    "\n",
    "#### First let's take a look on what LangChain say about `Text splitters`:\n",
    "\n",
    "> Document splitting is often a crucial preprocessing step for many applications. It involves breaking down large texts into smaller, manageable chunks. This process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems. There are several strategies for splitting documents, each with its own advantages.\n",
    "\n",
    "\n",
    "There are so many types of Loaders, each loader has it's own limitations and used for different types of documents.\n",
    "\n",
    "Like `PyPDFLoader` is used to load PDFs, `WebBaseLoader` are used to load web pages. In the same way different splitters are used for different tasks, depending on what we need to split.\n",
    "\n",
    "Some of the Common Splitters in LangChain are:\n",
    "\n",
    "\n",
    "1. `CharacterTextSplitter` - Splits text based on character count, ensuring each chunk stays under a specified length.\n",
    "   \n",
    "2. `RecursiveCharacterTextSplitter` - Splits text hierarchically by breaking it down into smaller sections while respecting delimiters like paragraphs or sentences.\n",
    "   \n",
    "3. `MarkdownTextSplitter` - Splits text based on Markdown formatting, keeping logical structures like headings and lists intact.\n",
    "\n",
    "4. `TokenTextSplitter` - Splits text by token count, often using tokenizer models to match LLM tokenization logic.\n",
    "\n",
    "5. `LanguageSplitter` - Splits code files by programming language or structure.\n",
    "\n",
    "6. `PythonCodeSplitter` - Specializes in splitting Python code into logical units like functions or classes.\n",
    "\n",
    "7. `HTMLHeaderTextSplitter` - Splits HTML documents into meaningful parts such as tags, paragraphs, or sections.\n",
    "\n",
    "8.  `XMLSplitter` - Splits XML files while preserving the structure of nodes and tags.\n",
    "\n",
    "9.  `CustomSplitter` - A user-defined splitter for specialized splitting requirements\n",
    "\n",
    "10. `NLTKTextSplitter` - Splitting text using NLTK package. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `CharacterTextSplitter` to split the Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters:\n",
    "- separator: Delimiter for splitting (default: \" \").\n",
    "- chunk_size: Maximum size of each chunk.\n",
    "- chunk_overlap: Number of overlapping characters between chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('./Data/Central_Limit_Theorem.pdf')\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './Data/Central_Limit_Theorem.pdf', 'page': 0}, page_content='Bernoulli distribution is a probability distribution that models a binary outcome, where the \\noutcome can be either success (represented by the value 1) or failure (represented by the \\nvalue 0). The Bernoulli distribution is named after the Swiss mathematician Jacob Bernoulli, \\nwho first introduced it in the late 1600s.\\nThe Bernoulli distribution is characterized by a single parameter, which is the probability of \\nsuccess, denoted by p. The probability mass function (PMF) of the Bernoulli distribution is:\\nThe Bernoulli distribution is commonly used in machine learning for modelling \\nbinary outcomes, such as whether a customer will make a purchase or not, \\nwhether an email is spam or not, or whether a patient will have a certain disease \\nor not.\\nBernoulli Distribution\\n27 March 2023 16:06\\n   Session on Central Limit Theorem Page 1    ')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\", # Separator will help us to split the docs from where we want to split\n",
    "                                 chunk_size=120,\n",
    "                                 chunk_overlap=50) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most of the cases when we are dealing with this we often came accross these two methods in splitters.\n",
    "\n",
    "#### 1. split_documents\n",
    "#### 2. split_text\n",
    "\n",
    "#### Let's see what is the difference between both of them:\n",
    "\n",
    "The primary difference between split_text and split_documents in LangChain lies in what they process and the type of output they generate:\n",
    "\n",
    "- 1. split_text\n",
    "      - Purpose: Splits a single string of text into smaller chunks.\n",
    "      - Input: A single string (e.g., raw text or the contents of a file).\n",
    "      - Output: A list of strings, where each string is a chunk of the original text.\n",
    "      - Use Case: When you want to split raw text directly into manageable pieces, often for tasks like tokenization or summarization.\n",
    "- 2. split_documents\n",
    "      - Purpose: Splits multiple documents into chunks.\n",
    "      - Input: A list of documents, where each document is a dictionary with at least a page_content key containing text.\n",
    "      - Output: A list of dictionaries, where each dictionary is a chunk of a document and retains metadata.\n",
    "      - Use Case: When working with structured data (e.g., multiple documents) and you want to preserve metadata (e.g., document source, page number)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Use split_text for simple, unstructured text, and use split_documents for more complex workflows where you need to manage multiple documents along with their metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_text_splitters.base:Created a chunk of size 228, which is longer than the specified 120\n"
     ]
    }
   ],
   "source": [
    "splitter = CharacterTextSplitter(separator=\"\\n\", # Separator will help us to split the docs from where we want to split\n",
    "                                 chunk_size=120,\n",
    "                                 chunk_overlap=50) \n",
    "\n",
    "text = \"\"\"Document splitting is often a crucial preprocessing step for many applications.\n",
    "It involves breaking down large texts into smaller, manageable chunks. \n",
    "This process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems. \n",
    "There are several strategies for splitting documents, each with its own advantages.\"\"\"\n",
    "\n",
    "chunk = splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Document splitting is often a crucial preprocessing step for many applications.',\n",
       " 'It involves breaking down large texts into smaller, manageable chunks.',\n",
       " 'This process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems.',\n",
       " 'There are several strategies for splitting documents, each with its own advantages.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `RecursiveSplitter` to split the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.word_document import Docx2txtLoader\n",
    "\n",
    "loader = Docx2txtLoader('./Data/RAG_Types_Table.docx')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='RAG Types: Advantages, Disadvantages, Use Cases, and Additional Information\\n\\nRAG Type\\n\\nAdvantages\\n\\nDisadvantages\\n\\nWhen to Use\\n\\nAdditional Information\\n\\nHybrid RAG\\n\\n- High accuracy by combining multiple information sources\\n- Handles diverse types of data (structured, unstructured) well\\n- Robust in challenging scenarios\\n\\n- Complexity in implementation\\n- Higher computational resources required\\n- Increased latency\\n\\n- When accuracy is paramount, and there are multiple data types\\n\\nCombines retrieval-based techniques (like search engines or databases) and generation-based techniques (like GPT-based models) to provide comprehensive responses.\\n\\nGenerative RAG\\n\\n- Provides flexible and creative responses\\n- Can generate human-like content\\n- Capable of handling open-domain questions\\n\\n- Risk of generating hallucinated information\\n- Requires more extensive training data\\n\\n- For open-ended or creative tasks, generating human-like answers\\n\\nFocuses more on generative approaches by leveraging large language models (LLMs) to generate answers, which may include context-based information fetched from external sources.\\n\\nRetrieval RAG\\n\\n- Provides precise, contextually relevant information\\n- Efficiently scales with large data\\n- Suitable for factual accuracy\\n\\n- Limited flexibility in response generation\\n- May not adapt well to highly abstract or creative tasks\\n\\n- When factual correctness is a priority\\n\\nPrimarily relies on robust retrieval systems such as search engines or database queries to provide pre-fetched content that is more factual and contextually accurate.\\n\\nKnowledge-based RAG\\n\\n- Integrates domain-specific knowledge\\n- High reliability in specific domains\\n- Supports real-time information and knowledge updates\\n\\n- Limited to the knowledge base updates\\n- May not perform well in general contexts\\n\\n- When domain-specific knowledge is required\\n\\nUses a structured knowledge base to answer questions, making it ideal for use cases like medical consultations, technical troubleshooting, and specialized customer support.\\n\\nEnd-to-End RAG\\n\\n- Seamless integration of retrieval and generation\\n- Provides a unified framework\\n- Can be fine-tuned for specific applications\\n\\n- Difficult to debug errors in responses\\n- High model complexity\\n\\n- When there is a need for streamlined, single-model architecture\\n\\nThese RAG systems combine both retrieval and generation processes in a tightly integrated end-to-end model, making them suitable for applications requiring high cohesion between information retrieval and generation.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.character import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='RAG Types: Advantages, Disadvantages, Use Cases, and Additional Information\\n\\nRAG Type\\n\\nAdvantages'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Disadvantages\\n\\nWhen to Use\\n\\nAdditional Information\\n\\nHybrid RAG'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- High accuracy by combining multiple information sources'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Handles diverse types of data (structured, unstructured) well\\n- Robust in challenging scenarios'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Complexity in implementation\\n- Higher computational resources required\\n- Increased latency'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- When accuracy is paramount, and there are multiple data types'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Combines retrieval-based techniques (like search engines or databases) and generation-based'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='techniques (like GPT-based models) to provide comprehensive responses'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='.'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Generative RAG'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Provides flexible and creative responses\\n- Can generate human-like content'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Capable of handling open-domain questions'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Risk of generating hallucinated information\\n- Requires more extensive training data'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- For open-ended or creative tasks, generating human-like answers'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Focuses more on generative approaches by leveraging large language models (LLMs) to generate'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='answers, which may include context-based information fetched from external sources'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='.'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Retrieval RAG'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Provides precise, contextually relevant information\\n- Efficiently scales with large data'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Suitable for factual accuracy'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Limited flexibility in response generation'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- May not adapt well to highly abstract or creative tasks'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- When factual correctness is a priority'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Primarily relies on robust retrieval systems such as search engines or database queries to provide'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='pre-fetched content that is more factual and contextually accurate'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='.'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Knowledge-based RAG'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Integrates domain-specific knowledge\\n- High reliability in specific domains'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Supports real-time information and knowledge updates'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Limited to the knowledge base updates\\n- May not perform well in general contexts'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- When domain-specific knowledge is required'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='Uses a structured knowledge base to answer questions, making it ideal for use cases like medical'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='consultations, technical troubleshooting, and specialized customer support'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='.'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='End-to-End RAG'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Seamless integration of retrieval and generation\\n- Provides a unified framework'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Can be fine-tuned for specific applications'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- Difficult to debug errors in responses\\n- High model complexity'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='- When there is a need for streamlined, single-model architecture'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='These RAG systems combine both retrieval and generation processes in a tightly integrated'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='end-to-end model, making them suitable for applications requiring high cohesion between information'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='retrieval and generation'),\n",
       " Document(metadata={'source': './Data/RAG_Types_Table.docx'}, page_content='.')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "chunk = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Document splitting is often a crucial preprocessing step for many applications.',\n",
       " 'It involves breaking down large texts into smaller, manageable chunks.',\n",
       " 'This process offers several benefits, such as ensuring consistent processing of varying document',\n",
       " 'lengths, overcoming input size limitations of models, and improving the quality of text',\n",
       " 'representations used in retrieval systems',\n",
       " '.',\n",
       " 'There are several strategies for splitting documents, each with its own advantages.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `TokenTextSplitter` to split the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different methods to split our Data into tokens.\n",
    "\n",
    "We can use `TokenTextSplitter` and also with `CharacterTextSplitter` and `RecursiveCharacterTextSplitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.base import TokenTextSplitter\n",
    "\n",
    "splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "\n",
    "chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Document splitting is often a crucial preprocessing step for many applications.\\nIt involves breaking down large texts into smaller, manageable chunks. \\nThis process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems. \\nThere are several strategies for splitting documents, each with its own advantages.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=100, chunk_overlap=0\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=100, chunk_overlap=0\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `MarkdownTextSplitter` to split markdown files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "loader = UnstructuredMarkdownLoader('./Data/mark.md')\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './Data/mark.md'}, page_content='Hello\\n\\nHello\\n\\nHello\\n\\nHello\\n\\nThis is my book\\n\\nThis is my book\\n\\nThis is my book.\\n\\nThis is my book\\n\\nHi\\n\\n__Hello__\\n\\nhello\\n\\nhello\\n\\nHello\\n\\nHi\\n\\nhi\\n\\nHello\\n\\nHello\\n\\nhi\\\\\\n\\nBooks\\n\\nThis is my book')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.markdown import MarkdownTextSplitter\n",
    "splitter = MarkdownTextSplitter(chunk_size=50, chunk_overlap=0)\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Data/mark.md'}, page_content='Hello\\n\\nHello\\n\\nHello\\n\\nHello\\n\\nThis is my book'),\n",
       " Document(metadata={'source': './Data/mark.md'}, page_content='This is my book\\n\\nThis is my book.'),\n",
       " Document(metadata={'source': './Data/mark.md'}, page_content='This is my book\\n\\nHi\\n\\n__Hello__\\n\\nhello\\n\\nhello'),\n",
       " Document(metadata={'source': './Data/mark.md'}, page_content='Hello\\n\\nHi\\n\\nhi\\n\\nHello\\n\\nHello\\n\\nhi\\\\\\n\\nBooks'),\n",
       " Document(metadata={'source': './Data/mark.md'}, page_content='This is my book')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split `language code` using `LanguageSplitter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RecursiveCharacterTextSplitter` includes pre-built lists of separators that are useful for splitting text in a specific programming language.\n",
    "\n",
    "Supported languages are stored in the langchain_text_splitters.Language enum. They include:\n",
    "\n",
    "\"cpp\",\n",
    "\"go\",\n",
    "\"java\",\n",
    "\"kotlin\",\n",
    "\"js\",\n",
    "\"ts\",\n",
    "\"php\",\n",
    "\"proto\",\n",
    "\"python\",\n",
    "\"rst\",\n",
    "\"ruby\",\n",
    "\"rust\",\n",
    "\"scala\",\n",
    "\"swift\",\n",
    "\"markdown\",\n",
    "\"latex\",\n",
    "\"html\",\n",
    "\"sol\",\n",
    "\"csharp\",\n",
    "\"cobol\",\n",
    "\"c\",\n",
    "\"lua\",\n",
    "\"perl\",\n",
    "\"haskell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
    "\n",
    "JS_CODE = \"\"\"\n",
    "function helloWorld() {\n",
    "  console.log(\"Hello, World!\");\n",
    "}\n",
    "\n",
    "// Call the function\n",
    "helloWorld();\n",
    "\"\"\"\n",
    "\n",
    "js_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.JS, chunk_size=60, chunk_overlap=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='function helloWorld() {\\n  console.log(\"Hello, World!\");\\n}'),\n",
       " Document(metadata={}, page_content='// Call the function\\nhelloWorld();')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_docs = js_splitter.create_documents([JS_CODE])\n",
    "js_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='<!DOCTYPE html>\\n<html>'),\n",
       " Document(metadata={}, page_content='<head>\\n        <title>🦜️🔗 LangChain</title>'),\n",
       " Document(metadata={}, page_content='<style>\\n            body {\\n                font-family: Aria'),\n",
       " Document(metadata={}, page_content='l, sans-serif;\\n            }\\n            h1 {'),\n",
       " Document(metadata={}, page_content='color: darkblue;\\n            }\\n        </style>\\n    </head'),\n",
       " Document(metadata={}, page_content='>'),\n",
       " Document(metadata={}, page_content='<body>'),\n",
       " Document(metadata={}, page_content='<div>\\n            <h1>🦜️🔗 LangChain</h1>'),\n",
       " Document(metadata={}, page_content='<p>⚡ Building applications with LLMs through composability ⚡'),\n",
       " Document(metadata={}, page_content='</p>\\n        </div>'),\n",
       " Document(metadata={}, page_content='<div>\\n            As an open-source project in a rapidly dev'),\n",
       " Document(metadata={}, page_content='eloping field, we are extremely open to contributions.'),\n",
       " Document(metadata={}, page_content='</div>\\n    </body>\\n</html>')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_text = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>🦜️🔗 LangChain</title>\n",
    "        <style>\n",
    "            body {\n",
    "                font-family: Arial, sans-serif;\n",
    "            }\n",
    "            h1 {\n",
    "                color: darkblue;\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div>\n",
    "            <h1>🦜️🔗 LangChain</h1>\n",
    "            <p>⚡ Building applications with LLMs through composability ⚡</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            As an open-source project in a rapidly developing field, we are extremely open to contributions.\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "html_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.HTML, chunk_size=60, chunk_overlap=0\n",
    ")\n",
    "html_docs = html_splitter.create_documents([html_text])\n",
    "html_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='def hello_world():\\n    print(\"Hello, World!\")'),\n",
       " Document(metadata={}, page_content='# Call the function\\nhello_world()')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using `HTMLHeaderTextSplitter` to split HTML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "\n",
    "loader = BSHTMLLoader('./Data/langchain.html')\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='\\n\\nBSHTMLLoader | 🦜️🔗 LangChain\\n\\n\\n\\n\\n\\n\\nSkip to main contentIntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchKProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAcreomActiveloop Deep LakeAerospikeAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)BrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextCouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeepSparseDiffbotDingoDBDiscordDocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDSPyDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFalkorDBFaunaFiddlerFigmaFireCrawlFireworks AIFlyteForefront AIFriendli AIGeopandasGitGitBookGitHubGitLabGoldenGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraphsignalGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYKùzuLabel StudiolakeFSLanceDBLangChain Decorators ✨LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariTalkMarqoMediaWikiDumpMeilisearchMemcachedMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMotörheadMyScaleNAVERNeo4jNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesPandasPebbloPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPremAIPromptLayerPsychicPubMedPullMd LoaderPygmalionAIQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRWKV-4Salute DevicesSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStoreDBscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)NebulaTairTelegramTencentTensorFlow DatasetsTiDBTigerGraphTigrisTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchVDMSVearchVectaraVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterxAIXataXorbits Inference (Xinference)YahooYandexYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizComponentsChat modelsChat modelsAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflare Workers AICohereCoze ChatDappier AIDatabricksDeepInfraEden AIErnie Bot ChatEverlyAIFireworksChatFriendliGigaChatGoogle AIGoogle Cloud Vertex AIGPTRouterGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLiteLLM RouterLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityChatPredictionGuardPremAIPromptLayer ChatOpenAIRekaSambaNovaCloudSambaStudioSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevLLM ChatVolc Enging MaasWriterxAIYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCohere rerankerCohere RAGDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGoogle DriveGoogle Vertex AI SearchIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalMilvus Hybrid SearchNanoPQ (Product Quantization)needleOutlinePinecone Hybrid SearchPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSingleStoreDBSVMTavilySearchAPITF-IDF**NeuralDB**VespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineTools/ToolkitsToolsAINetwork ToolkitAlpha VantageAmadeus ToolkitArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchE2B Data AnalysisEden AIEleven Labs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitGithub ToolkitGitlab ToolkitGmail ToolkitGolden QueryGoogle BooksGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksInfobipIonic Shopping ToolJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenWeatherMapOracle AI Vector Search: Generate SummaryPandas DataframePassio NutritionAIPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTavily SearchTwilioUpstageWikidataWikipediaWolfram AlphaYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modePandas DataFrameparsersPDFMinerPDFPlumberPebblo Safe DocumentLoaderPolars DataFramePsychicPubMedPullMdLoaderPyMuPDFPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCouchbaseDashVectorDatabricksDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconeQdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStoreDBscikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdIntel\\'s Visual Data Management System (VDMS)VearchVectaraVespaviking DBvliteWeaviateXataYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGigaChatGoogle Generative AI EmbeddingsGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel® Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsDocument loadersBSHTMLLoaderOn this pageBSHTMLLoader\\nThis notebook provides a quick overview for getting started with BeautifulSoup4 document loader. For detailed documentation of all __ModuleName__Loader features and configurations head to the API reference.\\nOverview\\u200b\\nIntegration details\\u200b\\nClassPackageLocalSerializableJS supportBSHTMLLoaderlangchain_community✅❌❌\\nLoader features\\u200b\\nSourceDocument Lazy LoadingNative Async SupportBSHTMLLoader✅❌\\nSetup\\u200b\\nTo access BSHTMLLoader document loader you\\'ll need to install the langchain-community integration package and the bs4 python package.\\nCredentials\\u200b\\nNo credentials are needed to use the BSHTMLLoader class.\\nIf you want to get automated best in-class tracing of your model calls you can also set your LangSmith API key by uncommenting below:\\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\\nInstallation\\u200b\\nInstall langchain_community and bs4.\\n%pip install -qU langchain_community bs4\\nInitialization\\u200b\\nNow we can instantiate our model object and load documents:\\n\\nTODO: Update model instantiation with relevant params.\\n\\nfrom langchain_community.document_loaders import BSHTMLLoaderloader = BSHTMLLoader(    file_path=\"./example_data/fake-content.html\",)API Reference:BSHTMLLoader\\nLoad\\u200b\\ndocs = loader.load()docs[0]\\nDocument(metadata={\\'source\\': \\'./example_data/fake-content.html\\', \\'title\\': \\'Test Title\\'}, page_content=\\'\\\\nTest Title\\\\n\\\\n\\\\nMy First Heading\\\\nMy first paragraph.\\\\n\\\\n\\\\n\\')\\nprint(docs[0].metadata)\\n{\\'source\\': \\'./example_data/fake-content.html\\', \\'title\\': \\'Test Title\\'}\\nLazy Load\\u200b\\npage = []for doc in loader.lazy_load():    page.append(doc)    if len(page) >= 10:        # do some paged operation, e.g.        # index.upsert(page)        page = []page[0]\\nDocument(metadata={\\'source\\': \\'./example_data/fake-content.html\\', \\'title\\': \\'Test Title\\'}, page_content=\\'\\\\nTest Title\\\\n\\\\n\\\\nMy First Heading\\\\nMy first paragraph.\\\\n\\\\n\\\\n\\')\\nAdding separator to BS4\\u200b\\nWe can also pass a separator to use when calling get_text on the soup\\nloader = BSHTMLLoader(    file_path=\"./example_data/fake-content.html\", get_text_separator=\", \")docs = loader.load()print(docs[0])\\npage_content=\\', Test Title, , , , My First Heading, , My first paragraph., , , \\' metadata={\\'source\\': \\'./example_data/fake-content.html\\', \\'title\\': \\'Test Title\\'}\\nAPI reference\\u200b\\nFor detailed documentation of all BSHTMLLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.html_bs.BSHTMLLoader.html\\nRelated\\u200b\\n\\nDocument loader conceptual guide\\nDocument loader how-to guides\\nEdit this pageWas this page helpful?PreviousBrowserlessNextCassandraOverviewIntegration detailsLoader featuresSetupCredentialsInstallationInitializationLoadLazy LoadAdding separator to BS4API referenceRelatedCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.\\n')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.html import HTMLHeaderTextSplitter\n",
    "\n",
    "splitter = HTMLHeaderTextSplitter(headers_to_split_on=[\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='BSHTMLLoader | 🦜️🔗 LangChain\\n\\n\\n\\n\\n\\n\\nSkip to main contentInt'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='egrationsAPI ReferenceMoreContributingPeopleError referenceL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='angSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='1💬SearchKProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='nAIMoreProvidersAcreomActiveloop Deep LakeAerospikeAI21 Labs'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='AimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAn'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='alyticDBAnnoyAnthropicAnyscaleApache Software FoundationApac'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='he DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxiv'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='AscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsBAAIBage'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='lBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='liBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Op'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='en Knowledge)BrowserbaseBrowserlessByteDanceCassandraCerebra'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='sCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpC'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='loudflareClovaCnosDBCogniSwitchCohereCollege ConfidentialCom'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='etConfident AIConfluenceConneryContextCouchbaseCozeCrateDBC'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='TransformersCTranslate2CubeDappierDashVectorDatabricksDatado'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='g TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeepS'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='parseDiffbotDingoDBDiscordDocArrayDoclingDoctranDocugamiDocu'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='saurusDriaDropboxDSPyDuckDBDuckDuckGo SearchE2BEden AIElasti'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='csearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNote'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ExaFacebook - MetaFalkorDBFalkorDBFaunaFiddlerFigmaFireCrawl'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Fireworks AIFlyteForefront AIFriendli AIGeopandasGitGitBookG'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='itHubGitLabGoldenGoogleSerper - Google Search APIGooseAIGPT4'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='AllGradientGraphsignalGrobidGroqGutenbergHacker NewsHazy Res'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='earchHeliconeHologresHTML to textHuaweiHugging FaceIBMIEIT S'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIugu'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='JaguarJavelin AI GatewayJina AIJohnsnowlabsJoplinKDB.AIKinet'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='icaKoboldAIKonkoKoNLPYKùzuLabel StudiolakeFSLanceDBLangChain'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Decorators ✨LanternLindormLinkupLiteLLMLlamaIndexLlama.cppL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='lamaEdgellamafileLLMonitorLocalAILog10MariTalkMarqoMediaWiki'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='DumpMeilisearchMemcachedMetalMicrosoftMilvusMindsDBMinimaxMi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='stralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeMod'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMotörheadMy'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ScaleNAVERNeo4jNLPCloudNomicNotion DBNucliaNVIDIAObsidianOce'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='anBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='GraphDBOpenAIOpenLLMOpenSearchOpenWeatherMapOracleAI Vector'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='SearchOutlineOutlinesPandasPebbloPerplexityPetalsPostgres Em'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='beddingPGVectorPineconePipelineAIPortkeyPredibasePrediction'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='GuardPremAIPromptLayerPsychicPubMedPullMd LoaderPygmalionAIQ'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='drantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembral'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='lReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRWKV-4Salut'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='e DevicesSAPScrapeGraph AISearchApiSearxNG Search APISemaDBS'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='erpAPIShale ProtocolSingleStoreDBscikit-learnSlackSnowflakes'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='paCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStocha'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='sticAIStreamlitStripeSupabase (Postgres)NebulaTairTelegramTe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ncentTensorFlow DatasetsTiDBTigerGraphTigrisTogether AI2Mark'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='downTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructur'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='edUpstageupstashUpTrainUSearchVDMSVearchVectaraVespavliteVoy'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ageAIWeights & BiasesWeights & Biases tracingWeights & Biase'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='s trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram Alp'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='haWriterxAIXataXorbits Inference (Xinference)YahooYandexYeag'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='er.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizComponentsCh'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='at modelsChat modelsAI21 LabsAlibaba Cloud PAI EASAnthropic['),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzur'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='e OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS Bedro'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ckCerebrasCloudflare Workers AICohereCoze ChatDappier AIData'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='bricksDeepInfraEden AIErnie Bot ChatEverlyAIFireworksChatFri'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='endliGigaChatGoogle AIGoogle Cloud Vertex AIGPTRouterGroqCha'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='tHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLiteLL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='M RouterLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniM'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='axMistralAIMLXModelScopeMoonshotNaverNVIDIA AI EndpointsChat'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='OCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerp'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='lexityChatPredictionGuardPremAIPromptLayer ChatOpenAIRekaSam'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='baNovaCloudSambaStudioSnowflake CortexsolarSparkLLM ChatNebu'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='la (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevLLM C'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='hatVolc Enging MaasWriterxAIYandexGPTChatYIYuan2.0ZHIPU AIRe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='trieversRetrieversActiveloop Deep MemoryAmazon KendraArceeAr'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='xivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBRE'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='EBS (Open Knowledge)ChaindeskChatGPT pluginCohere rerankerCo'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='here RAGDappierDocArrayDriaElasticSearch BM25ElasticsearchEm'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='bedchainFlashRank rerankerFleet AI ContextGoogle DriveGoogle'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Vertex AI SearchIBM watsonx.aiJaguarDB Vector DatabaseKay.a'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='iKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieve'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='rLLMLingua Document CompressorLOTR (Merger Retriever)MetalMi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='lvus Hybrid SearchNanoPQ (Product Quantization)needleOutline'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Pinecone Hybrid SearchPubMedQdrant Sparse VectorRAGatouilleR'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ePhraseQueryRememberizerSEC filingSelf-querying retrieversSi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ngleStoreDBSVMTavilySearchAPITF-IDF**NeuralDB**VespaWikipedi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='aYou.comZep CloudZep Open SourceZilliz Cloud PipelineTools/T'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oolkitsToolsAINetwork ToolkitAlpha VantageAmadeus ToolkitArX'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Services ToolkitAzure Container Apps dynamic sessionsShell ('),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='bash)Bearly Code InterpreterBing SearchBrave SearchCassandra'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitc'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='h ToolkitConnery Toolkit and ToolsDall-E Image GeneratorData'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='bricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo Sear'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='chE2B Data AnalysisEden AIEleven Labs Text2SpeechExa SearchF'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ile SystemFinancialDatasets ToolkitGithub ToolkitGitlab Tool'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='kitGmail ToolkitGolden QueryGoogle BooksGoogle Cloud Text-to'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoo'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='gle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle Serpe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='rGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a t'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oolIFTTT WebHooksInfobipIonic Shopping ToolJina SearchJira T'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oolkitJSON ToolkitLemon AgentLinkupSearchToolMemorizeMojeek'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='SearchMultiOn ToolkitNASA ToolkitNuclia UnderstandingNVIDIA'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Lan'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='guage API ToolkitsOpenWeatherMapOracle AI Vector Search: Gen'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='erate SummaryPandas DataframePassio NutritionAIPlayWright Br'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='owser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPubM'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='edPython REPLReddit SearchRequests ToolkitRiza Code Interpre'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='terRobocorp ToolkitSceneXplainScrapeGraphSearchApiSearxNG Se'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='archSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL T'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTav'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ily SearchTwilioUpstageWikidataWikipediaWolfram AlphaYahoo F'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='inance NewsYou.com SearchYouTubeZapier Natural Language Acti'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='onsZenGuard AIDocument loadersDocument loadersacreomAirbyteL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyt'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='e Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Sales'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='force (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='(Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Su'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='pport (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon Tex'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='tractApify DatasetArcGISArxivLoaderAssemblyAI Audio Transcri'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='liBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessB'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='SHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurre'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='nt LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semanti'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='c LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusau'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='rusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebo'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ok ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue Cata'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='logGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle Bigtab'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='leGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLG'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oogle Cloud SQL for PostgreSQLGoogle Cloud Storage Directory'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Google Cloud Storage FileGoogle Firestore in Datastore ModeG'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firest'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ore (Native Mode)Google Memorystore for RedisGoogle SpannerG'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiF'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter Not'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMast'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='odonMathPixPDFLoaderMediaWiki DumpMerge Documents Loadermhtm'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='lMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='PowerPointMicrosoft SharePointMicrosoft WordNear Blockchain'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Modern TreasuryMongoDBNeedle Document LoaderNews URLNotion D'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='B 2/2NucliaObsidianOpen Document Format (ODT)Open City DataO'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='racle Autonomous DatabaseOracle AI Vector Search: Document P'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='rocessingOrg-modePandas DataFrameparsersPDFMinerPDFPlumberPe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='bblo Safe DocumentLoaderPolars DataFramePsychicPubMedPullMdL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oaderPyMuPDFPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPy'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='SparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRoc'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ksetrspaceRSS FeedsRSTscrapflyScrapingAntSitemapSlackSnowfla'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='keSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTe'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ncent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2M'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='arkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoader'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='WhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas Da'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='taFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZ'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='eroxPDFLoaderVector storesVector storesActiveloop Deep LakeA'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='erospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisA'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='pertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mong'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='o vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaid'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='u Cloud ElasticSearch VectorSearchBaidu VectorDBApache Cassa'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ndraChromaClarifaiClickHouseCouchbaseDashVectorDatabricksDin'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='goDBDocArray HnswSearchDocArray InMemorySearchAmazon Documen'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='t DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElas'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGoogle'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cl'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoo'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='gle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feat'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ure StoreGoogle Vertex AI Vector SearchHippoHologresInfinisp'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='anJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormL'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='LMRailsManticoreSearch VectorStoreMarqoMeilisearchAmazon Mem'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='4j Vector IndexNucliaDBOceanbaseOpenSearchOracle AI Vector S'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='earch: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVect'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='orPineconeQdrantRedisRelytRocksetSAP HANA Cloud Vector Engin'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='eScaNNSemaDBSingleStoreDBscikit-learnSQLiteVecSQLite-VSSSQLS'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='erverStarRocksSupabase (Postgres)SurrealDBTablestoreTairTenc'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTim'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='escale Vector (Postgres)TypesenseUpstash VectorUSearchValdIn'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"tel's Visual Data Management System (VDMS)VearchVectaraVespa\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='viking DBvliteWeaviateXataYellowbrickZepZep CloudZillizEmbed'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaD'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='BAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticse'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='archEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='gaChatGoogle Generative AI EmbeddingsGoogle Vertex AIGPT4All'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='GradientHugging FaceIBM watsonx.aiInfinityInstruct Embedding'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='s on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPU'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='IPEX-LLM: Local BGE Embeddings on Intel GPUIntel® Extension'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='for Transformers Quantized Text EmbeddingsJinaJohn Snow Labs'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='LASER Language-Agnostic SEntence Representations Embeddings'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMis'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='tralAImodel2vecModelScopeMosaicMLNaverNLP CloudNomicNVIDIA N'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='IMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOp'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='enAIOpenVINOEmbedding Documents using Optimized and Quantize'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='d EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcl'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='oudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMak'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='erSambaNovaSelf HostedSentence Transformers on Hugging FaceS'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='olarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddin'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='gs InferenceTextEmbed - Embedding Inference ServerTitan Take'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='offTogether AIUpstageVolc EngineVoyage AIXorbits inference ('),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Xinference)YandexGPTZhipuAIOtherComponentsDocument loadersBS'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='HTMLLoaderOn this pageBSHTMLLoader\\nThis notebook provides a'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='quick overview for getting started with BeautifulSoup4 docum'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ent loader. For detailed documentation of all __ModuleName__'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Loader features and configurations head to the API reference'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='.\\nOverview\\u200b\\nIntegration details\\u200b\\nClassPackageLocalSerializab'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='leJS supportBSHTMLLoaderlangchain_community✅❌❌\\nLoader featur'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='es\\u200b\\nSourceDocument Lazy LoadingNative Async SupportBSHTMLLoa'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"der✅❌\\nSetup\\u200b\\nTo access BSHTMLLoader document loader you'll n\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='eed to install the langchain-community integration package a'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='nd the bs4 python package.\\nCredentials\\u200b\\nNo credentials are n'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='eeded to use the BSHTMLLoader class.\\nIf you want to get auto'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='mated best in-class tracing of your model calls you can also'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='set your LangSmith API key by uncommenting below:\\n# os.envi'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ron[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangS'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='mith API key: \")# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\\nI'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='nstallation\\u200b\\nInstall langchain_community and bs4.\\n%pip insta'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ll -qU langchain_community bs4\\nInitialization\\u200b\\nNow we can in'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='stantiate our model object and load documents:\\n\\nTODO: Update'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='model instantiation with relevant params.\\n\\nfrom langchain_c'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ommunity.document_loaders import BSHTMLLoaderloader = BSHTML'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Loader(    file_path=\"./example_data/fake-content.html\",)API'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Reference:BSHTMLLoader\\nLoad\\u200b\\ndocs = loader.load()docs[0]\\nDo'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"cument(metadata={'source': './example_data/fake-content.html\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"', 'title': 'Test Title'}, page_content='\\\\nTest Title\\\\n\\\\n\\\\nM\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"y First Heading\\\\nMy first paragraph.\\\\n\\\\n\\\\n')\\nprint(docs[0].m\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"etadata)\\n{'source': './example_data/fake-content.html', 'tit\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"le': 'Test Title'}\\nLazy Load\\u200b\\npage = []for doc in loader.laz\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='y_load():    page.append(doc)    if len(page) >= 10:'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='# do some paged operation, e.g.        # index.upsert(page)'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"page = []page[0]\\nDocument(metadata={'source': './exam\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"ple_data/fake-content.html', 'title': 'Test Title'}, page_co\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"ntent='\\\\nTest Title\\\\n\\\\n\\\\nMy First Heading\\\\nMy first paragrap\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"h.\\\\n\\\\n\\\\n')\\nAdding separator to BS4\\u200b\\nWe can also pass a separ\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ator to use when calling get_text on the soup\\nloader = BSHTM'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='LLoader(    file_path=\"./example_data/fake-content.html\", ge'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='t_text_separator=\", \")docs = loader.load()print(docs[0])\\npag'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"e_content=', Test Title, , , , My First Heading, , My first\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"paragraph., , , ' metadata={'source': './example_data/fake-c\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content=\"ontent.html', 'title': 'Test Title'}\\nAPI reference\\u200b\\nFor deta\"),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='iled documentation of all BSHTMLLoader features and configur'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ations head to the API reference: https://python.langchain.c'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='om/api_reference/community/document_loaders/langchain_commun'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ity.document_loaders.html_bs.BSHTMLLoader.html\\nRelated\\u200b\\n\\nDoc'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ument loader conceptual guide\\nDocument loader how-to guides'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='Edit this pageWas this page helpful?PreviousBrowserlessNextC'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='assandraOverviewIntegration detailsLoader featuresSetupCrede'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='ntialsInstallationInitializationLoadLazy LoadAdding separato'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='r to BS4API referenceRelatedCommunityTwitterGitHubOrganizati'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='onPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangCha'),\n",
       " Document(metadata={'source': './Data/langchain.html', 'title': 'BSHTMLLoader | 🦜️🔗 LangChain'}, page_content='in, Inc.')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_header_splits = html_splitter.split_documents(docs)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create our custom splitter using LangChain `TextSplitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Part1', 'Part2', 'Part3']\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import TextSplitter\n",
    "\n",
    "class CustomSplitter(TextSplitter):\n",
    "    def split_text(self, text):\n",
    "        # Your custom splitting logic\n",
    "        return text.split(\";\")\n",
    "\n",
    "splitter = CustomSplitter(chunk_size=100, chunk_overlap=10)\n",
    "chunks = splitter.split_text(\"Part1;Part2;Part3\")\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Document splitting is often a crucial preprocessing step for many applications.\\nIt involves breaking down large texts into smaller, manageable chunks. \\nThis process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems. \\nThere are several strategies for splitting documents, each with its own advantages.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also split the documents using `NLTKTextSplitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.nltk import NLTKTextSplitter\n",
    "\n",
    "splitter = NLTKTextSplitter()\n",
    "\n",
    "chunk = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Document splitting is often a crucial preprocessing step for many applications.\\n\\nIt involves breaking down large texts into smaller, manageable chunks.\\n\\nThis process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems.\\n\\nThere are several strategies for splitting documents, each with its own advantages.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split the Python code Specifically using `PythonCodeTextSplitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.python import PythonLoader\n",
    "\n",
    "loader = PythonLoader('./Data/sms.py')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.python import PythonCodeTextSplitter\n",
    "\n",
    "splitter = PythonCodeTextSplitter()\n",
    "\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Data/sms.py'}, page_content='# Step 1: Dictionary to store student data\\nstudents = {}\\n\\n\\n# Step 2: Function to add a new student\\ndef add_student():\\n    name = input(\"Enter student\\'s name: \").title()\\n    age = int(input(f\"Enter {name}\\'s age: \"))\\n    marks = float(input(f\"Enter {name}\\'s marks: \"))\\n\\n    # Add student to the dictionary\\n    students[name] = {\"age\": age, \"marks\": marks}\\n    print(f\"Student {name} added successfully!\")\\n\\n\\n# Step 3: Function to update student marks\\ndef update_marks():\\n    name = input(\"Enter the student\\'s name to update marks: \").title()\\n\\n    if name in students:\\n        new_marks = float(input(f\"Enter new marks for {name}: \"))\\n        students[name][\"marks\"] = new_marks\\n        print(f\"{name}\\'s marks updated to {new_marks}!\")\\n    else:\\n        print(f\"Student {name} not found!\")\\n\\n\\n# Step 4: Function to display a student\\'s details\\ndef display_student():\\n    name = input(\"Enter the student\\'s name to display details: \").title()\\n\\n    if name in students:\\n        print(f\"Name: {name}\")\\n        print(f\"Age: {students[name][\\'age\\']}\")\\n        print(f\"Marks: {students[name][\\'marks\\']}\")\\n    else:\\n        print(f\"Student {name} not found!\")\\n\\n\\n# Step 5: Function to display all students\\ndef display_all_students():\\n    if students:\\n        print(\"\\\\nAll Students:\")\\n        for name, details in students.items():\\n            print(f\"Name: {name}, Age: {details[\\'age\\']}, Marks: {details[\\'marks\\']}\")\\n    else:\\n        print(\"No students added yet.\")\\n\\n# Step 8: Main menu\\ndef menu():\\n    while True:\\n        print(\"\\\\n--- Student Management System ---\")\\n        print(\"1. Add a new student\")\\n        print(\"2. Update student marks\")\\n        print(\"3. Display a student\\'s details\")\\n        print(\"4. Display all students\")\\n        # print(\"5. Find the top student\")\\n        # print(\"6. Calculate average marks\")\\n        print(\"5. Exit\")\\n\\n        choice = int(input(\"Enter your choice: \"))\\n\\n        if choice == 1:\\n            add_student()\\n        elif choice == 2:\\n            update_marks()\\n        elif choice == 3:\\n            display_student()\\n        elif choice == 4:\\n            display_all_students()\\n        elif choice == 5:\\n            print(\"Exiting the system. Goodbye!\")\\n            break\\n        else:\\n            print(\"Invalid choice. Please try again.\")\\n\\n\\n# Start the Student Management System\\nmenu()')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
